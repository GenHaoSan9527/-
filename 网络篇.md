## <font style="color:rgba(0, 0, 0, 0.88);">常见的 HTTP 状态码有哪些？</font>
  
常见的 HTTP 状态码分为五大类，每个状态码由三位数字组成，第一位数字表示类别：

1. <font style="color:rgba(0, 0, 0, 0.88);">1xx: 信息响应</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">100 Continue: 服务器已接收请求的初步部分，客户端应继续请求。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">101 Switching Protocols: 服务器同意切换协议，如从 HTTP 切换到 WebSocket。</font>
2. <font style="color:rgba(0, 0, 0, 0.88);">2xx: 成功</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">200 OK: 请求成功，服务器返回所请求的资源或数据。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">201 Created: 请求成功并创建了新的资源，常用于 POST 请求。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">204 No Content: 请求成功但服务器不返回任何内容，常用于删除操作。</font>
3. <font style="color:rgba(0, 0, 0, 0.88);">3xx: 重定向</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">301 Moved Permanently: 资源已永久移动到新的 URL，客户端应使用新 URL 访问。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">302 Found: 资源临时移动到新的 URL，客户端应继续使用原来的 URL。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">304 Not Modified: 资源未修改，客户端可以使用缓存版本。</font>
4. <font style="color:rgba(0, 0, 0, 0.88);">4xx: 客户端错误</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">400 Bad Request: 请求无效或语法错误，服务器无法处理。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">401 Unauthorized: 请求需要身份验证，客户端未提供有效的凭证。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">403 Forbidden: 服务器理解请求但拒绝执行，通常是权限问题。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">404 Not Found: 请求的资源在服务器上未找到。</font>
5. <font style="color:rgba(0, 0, 0, 0.88);">5xx: 服务器错误</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">500 Internal Server Error: 服务器内部错误，无法完成请求。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">502 Bad Gateway: 服务器作为网关或代理，从上游服务器接收到无效响应。</font>
    - <font style="color:rgba(0, 0, 0, 0.88);">503 Service Unavailable: 服务器暂时无法处理请求，通常是因为过载或维护。</font>

## <font style="color:rgba(0, 0, 0, 0.88);">HTTP 请求包含哪些内容，请求头和请求体有哪些类型？</font>
### HTTP 请求由以下几部分组成：
+ 请求行（Request Line）：包含请求方法（如GET、POST）、请求的资源路径（如 /index.html ）、以及HTTP协议版本（如HTTP/1.1）。
+ 请求头（Request Headers）：包含各种键值对，用于传递客户端环境、请求内容、认证信息等。 
+ 空行（Blank Line）：用于分隔请求头和请求体。
+ 请求体（Request Body）：仅在POST、PUT等方法中存在，包含需要发送到服务器的数据。

常见的请求头类型：

+ 通用头部（General Headers）：适用于请求和响应，如 Cache-Control 、Connection 等。
+ 请求头部（Request Headers）：特定于请求的头部，如 Host 、User-Agent 、Accept 、Authorization 等。 
+ 实体头部（Entity Headers）：描述请求体的头部，如 Content-Type 、Content-Length 。

请求体的类型：

+ 表单数据（Form Data）：application/x-www-form-urlencoded，用于提交表单数据。 
+ 多部分数据（Multipart Data）：multipart/form-data，用于上传文件或复杂表单数据。 
+ JSON数据：application/json，用于提交JSON格式的数据。 
+ XML数据：application/xml，用于提交XML格式的数据。 
+ 文本数据：text/plain，用于提交纯文本数据。



### 扩展知识
1. 请求方法
    - GET：请求指定的资源，通常用于获取数据，不包含请求体。
    - POST：向服务器提交数据，通常用于表单提交，数据在请求体中。
    - PUT：用于更新资源，数据也在请求体中。
    - DELETE：请求删除指定资源。
2. 请求头部
    - Host：指定请求的主机名及端口，HTTP/1.1中必须包含。
    - User-Agent：标识客户端信息，通常用于服务器端的统计和个性化服务。
    - Accept：指定客户端可接受的媒体类型，服务器可以根据此头部返回合适的内容。
    - Authorization：用于身份验证，包含凭证信息，如Basic或Bearer token。
3. 请求体
    - application/x-www-form-urlencoded：键值对形式的表单数据，通常用在简单表单提交。 
    - multipart/form-data：处理复杂表单，包括文件上传，内容按边界分割。 
    - 自定义数据格式：根据API需求，可能需要提交XML、JSON、甚至是二进制数据。不同的Content-Type可以标识数据格式。
4. 性能与安全
    - 缓存机制：通过Cache-Control和ETag等头部，客户端和服务器可以有效管理缓存，减少不必要的请求。
    - 压缩：Content-Encoding头部可以指定压缩方式，如gzip，以减少数据传输量。 
    - 安全性：Authorization和Cookie等头部涉及身份验证和会话管理，应注意保护敏感信息，防止中间人攻击等安全威胁。

## <font style="color:rgba(0, 0, 0, 0.88);">HTTP 中 GET 和 POST 的区别是什么？</font>


从 HTTP 的定义来看：

+ GET：用于获取资源，通常用于请求数据而不改变服务器状态。
+ POST：用于提交数据到服务器，通常会改变服务器的状态或产生副作用（如创建或更新资源）。

由于 HTTP 和浏览器等规定，它们在应用过程中会出现一些区别：

### 参数传递方式：
+ GET：参数通过 URL 拼接传递，暴露在请求 URL 中，具有可见性，长度有限（取决于浏览器和服务器）。
+ POST：参数放在请求体中，通常不可见且长度理论上没有限制，更适合传递大量数据（但是注意，POST 也可以在 URL 上放参数！）。

### 安全性：
+ GET：参数可见，数据容易暴露在浏览器历史记录、日志和缓存中，不适合传递敏感信息。
+ POST：数据放在请求体中，相对安全，但需要 HTTPS 才能保证数据加密传输。

### 幂等性：
+ GET：幂等（重复请求不会改变服务器状态）。
+ POST：非幂等（多次请求可能导致重复创建资源或执行多次相同操作）。

### 扩展知识
### GET 和 POST 的数据传输方式与限制
+ URL 长度限制：GET 请求中的参数通过 URL 传递，受 URL 长度限制。不同浏览器和服务器对 URL 长度限制不同，一般为 2048 字节左右，因此不适合大数据传输。
+ POST 请求体限制：POST 请求的数据放在请求体中，理论上无长度限制，适合传输较多的数据。但实际中服务器对请求体长度有配置限制，如 Nginx 默认限制为 1MB，可根据需求调整。

### GET和POST的数据安全性差异
+ GET请求暴露数据：由于GET请求的参数出现在URL中，可能被浏览器缓存、日志记录或历史记录保存，增加了信息泄露的风险，不适合传输敏感信息，如用户名、密码等。
+ POST请求相对安全：POST请求数据位于请求体中，尽管这并不提供加密保护，但比URL中传递更隐蔽。配合HTTPS加密传输可进一步确保数据安全。

### 缓存机制的不同
+ GET请求可缓存：GET请求可以被浏览器和CDN缓存，当请求同一个URL时可以直接返回缓存内容，减少服务器负载。适用于不频繁变动的资源，比如图片、静态页面。 
+ POST请求默认不缓存：大部分浏览器和缓存服务器不缓存POST请求，主要因为POST请求通常会对服务器数据产生影响（如创建、修改数据），需要确保请求每次都传递到服务器。

### 幂等性和安全性原则
+ GET的幂等性：GET请求是幂等的，重复多次请求对服务器资源没有影响。即使客户端多次请求同一URL，服务器的资源状态不会变化。 
+ POST的非幂等性：POST请求不是幂等的，重复的POST请求可能导致重复的数据创建或操作。例如，重复提交表单可能导致服务器多次生成同样的数据记录（除非业务代码做了特殊处理）。 
+ 安全性原则：在HTTP方法的安全性定义中，GET是安全的，因为它只获取数据，不对服务器状态产生影响，而POST可能会更改服务器数据，因此不是安全的操作。



## <font style="color:rgba(0, 0, 0, 0.88);">HTTP 1.0 和 2.0 有什么区别？</font>


HTTP/1.0版本主要增加以下几点：

+ 增加了HEAD、POST等新方法。
+ 增加了响应状态码。
+ 引入了头部，即请求头和响应头。
+ 在请求中加入了HTTP版本号。
+ 引入了Content-Type，使得传输的数据不再限于文本。

HTTP/1.1版本主要增加以下几点：

+ 新增了连接管理即keepalive，允许持久连接。 
+ 支持pipeline，无需等待前面的请求响应，即可发送第二次请求。 
+ 允许响应数据分块（chunked），即响应的时候不标明Content-Length，客户端就无法断开连接，直到收到服务端的EOF，利于传输大文件。 
+ 新增缓存的控制和管理。 
+ 加入了Host头，用在你一台机子部署了多个主机，然后多个域名解析又是同一个IP，此时加入了Host头就可以判断你到底是要访问哪个主机。

HTTP/2版本主要增加以下几点：

+ 是二进制协议，不再是纯文本。 
+ 支持一个TCP连接发起多请求，移除了pipeline。 
+ 利用HPACK压缩头部，减少数据传输量。 
+ 允许服务端主动推送数据。

## <font style="color:rgba(0, 0, 0, 0.88);">HTTP 2.0 和 3.0 有什么区别？</font>
### 回答重点
1. 基于的传输层协议不同：
+ HTTP/2：基于TCP，使用二进制分帧层（Binary Framing Layer）实现多路复用。
+ HTTP/3：基于UDP，使用QUIC协议（Quick UDP Internet Connections），提供类似TCP的可靠性和多路复用。
2. 性能和可靠性区别：
+ HTTP/2：解决了HTTP/1.x中的队头阻塞问题，但仍然受制于TCP的队头阻塞，尤其在高延迟或丢包情况下。
+ HTTP/3：通过QUIC协议，避免了TCP队头阻塞，即使在网络不稳定的情况下也能提供更好的性能。
3. 从安全性角度来看：
+ HTTP/2：可以使用TLS加密（HTTPS），但加密并非强制要求。 
+ HTTP/3：默认使用QUIC自带的TLS 1.3加密，安全性更高，且加密是强制的。
4. 从连接建立速度：
+ HTTP/2：需要TCP三次握手和TLS握手，连接建立相对较慢。 
+ HTTP/3：QUIC集成了连接建立和加密握手，连接建立速度更快，尤其在初次连接时。

### QUIC技术优势
QUIC，Quick UDP Internet Connections是一个基于UDP的传输协议，由Google开发，旨在替代TCP以提高网络传输性能和安全性。QUIC在传输层和应用层之间提供可靠、低延迟的传输服务。

QUIC（Quick UDP Internet Connections）是一种由Google开发的基于UDP的传输层协议，旨在改进HTTP/2的性能。QUIC的设计目标是减少连接延迟，提高传输效率和安全性。以下是QUIC的一些技术优势和细节：

### 技术优势
1. **低延迟连接建立**：
+ QUIC使用0 - RTT（Zero Round Trip Time）技术，可以在首次握手时减少延迟。对于已经建立过连接的客户端，可以直接发送数据，无需等待服务器的响应。
2. **内置加密**：
+ QUIC协议默认采用TLS 1.3进行端到端加密，从而提高了数据传输的安全性，并简化了协议设计，不再需要像TCP那样进行额外的加密层配置。
3. **减少了队头阻塞（Head - of - Line Blocking）**：
+ 与TCP不同，QUIC在每个连接内使用多个独立的流，这意味着一个流上的丢包不会阻塞其他流的数据传输，从而显著减少队头阻塞问题，提高传输效率。
4. **更快的拥塞控制**：
+ QUIC可以更快速地调整拥塞控制算法，因为它能够访问更多的上下文信息（如链路的RTT、丢包率等），且能够在应用层进行定制优化。
5. **连接迁移**：
+ QUIC支持连接迁移，当客户端的IP地址或网络环境变化时（例如从Wi - Fi切换到蜂窝网络），连接依然可以保持，不会像TCP那样中断。
6. **更高的带宽利用率**：
+ QUIC通过改进的流量控制机制，可以更好地利用可用带宽，从而提高传输速度和效率。

更多QUIC细节参见HTTP 1.0和2.0有什么区别? 内扩展知识HTTP 3.0时代

## <font style="color:rgba(0, 0, 0, 0.88);">HTTP 和 HTTPS 有什么区别？</font>
1. 数据传输安全性：
+ HTTP：数据以明文传输，容易被窃听、篡改。
+ HTTPS：通过SSL/TLS协议对数据进行加密传输，提供数据机密性和完整性保障。
2. 端口号：
+ HTTP：默认使用端口80。
+ HTTPS：默认使用端口443。
3. 性能：
+ HTTP：无加密过程，连接建立速度稍快。
+ HTTPS：基于HTTP上又加了SSL（Secure Sockets Layer）或TLS（Transport Layer Security）协议来实现的加密传输，加解密过程增加了计算开销，握手时间较长，但现代硬件和协议优化已使性能差距减小。
4. SEO影响：
+ HTTP：搜索引擎一般会降低未加密站点的排名。
+ HTTPS：搜索引擎更倾向于优先展示HTTPS网站。

## <font style="color:rgba(0, 0, 0, 0.88);">TCP 和 UDP 有什么区别？、</font>
TCP 提供了可靠、面向连接的传输，适用于需要数据完整性和顺序的场景  
UDP 则提供了更轻量、面向报文的传输，适用于实时性要求高的场景。

<font style="color:rgba(0, 0, 0, 0.88);">区别总结：</font>

| <font style="color:rgba(0, 0, 0, 0.88);">特性</font> | <font style="color:rgba(0, 0, 0, 0.88);">TCP</font> | <font style="color:rgba(0, 0, 0, 0.88);">UDP</font> |
| --- | --- | --- |
| <font style="color:rgba(0, 0, 0, 0.88);">连接方式</font> | <font style="color:rgba(0, 0, 0, 0.88);">面向连接</font> | <font style="color:rgba(0, 0, 0, 0.88);">无连接</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">可靠性</font> | <font style="color:rgba(0, 0, 0, 0.88);">提供可靠性，保证数据按顺序到达</font> | <font style="color:rgba(0, 0, 0, 0.88);">不可靠，不保证顺序或完整性</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">流量控制/拥塞控制</font> | <font style="color:rgba(0, 0, 0, 0.88);">提供流量控制和拥塞控制</font> | <font style="color:rgba(0, 0, 0, 0.88);">没有流量控制和拥塞控制</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">顺序保证</font> | <font style="color:rgba(0, 0, 0, 0.88);">保证数据顺序</font> | <font style="color:rgba(0, 0, 0, 0.88);">不保证数据顺序</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">头部大小</font> | <font style="color:rgba(0, 0, 0, 0.88);">较大（20字节及以上）</font> | <font style="color:rgba(0, 0, 0, 0.88);">较小（8字节）</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">性能</font> | <font style="color:rgba(0, 0, 0, 0.88);">较低，延迟大</font> | <font style="color:rgba(0, 0, 0, 0.88);">较高，延迟小</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">数据传输模式</font> | <font style="color:rgba(0, 0, 0, 0.88);">字节流传输模式</font> | <font style="color:rgba(0, 0, 0, 0.88);">数据报传输模式</font> |
| <font style="color:rgba(0, 0, 0, 0.88);">适用场景</font> | <font style="color:rgba(0, 0, 0, 0.88);">文件传输、Web、邮件等需要可靠性的应用</font> | <font style="color:rgba(0, 0, 0, 0.88);">实时通讯、语音、视频、游戏等高性能要求应用</font> |


![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745071941057-bb0603c8-8130-47a0-848e-ea43d2f53ff1.png)

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745071956579-fa2f334d-cc1d-49d9-9e0d-0e39cbfffb12.png)

### 基于 TCP 的协议列举
+ HTTP 协议：主要用于超文本和多媒体内容的协议。
+ HTTPS 协议：在 HTTP 协议上加了一层 SSL/TLS 的外壳，可靠性和安全性有了一定保证。 
+ FTP 协议：文件传输协议，常见的像学生上传作业到学校的 FTP 上。 
+ SMTP 协议：简单邮件传输协议，用于发送邮件的协议。 
+ POP3 协议：负责邮件接收的协议。

### 基于 UDP 的协议列举
+ HTTP 3.0 版本使用的是基于 UDP 的 QUIC 协议。 
+ DHCP 协议：动态主机配置协议，动态配置 IP 地址。 
+ DNS：域名解析系统，将域名转变为机器可读的 IP 地址。

## <font style="color:rgba(0, 0, 0, 0.88);">说说 TCP 的三次握手？</font>


<font style="color:rgb(28, 31, 35);">具体流程文字描述就是：客户端首先发送一个SYN（同步序列编号）消息给服务器，服务器收到后回复一个SYN-ACK（同步序列编号-确认）消息，最后客户端再发送一个ACK（确认）消息确认服务器已经收到SYN-ACK消息，从而完成三次握手，建立起一个可靠的TCP连接。 来看下这个图： </font>

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745072187475-22499590-d2b2-4f8c-90d0-d28bf1d0c258.png)

## <font style="color:rgba(0, 0, 0, 0.88);">TCP 是用来解决什么问题？</font>


TCP（Transmission Control Protocol）通过提供可靠传输、流量控制、拥塞控制和连接管理，解决了数据在不可靠的 IP 网络上的传输问题：

1. 可靠性传输：TCP 确保数据包在网络传输过程中不丢失、不重复，并且按顺序到达。通过确认（ACK）、重传机制以及序列号，TCP 能够保证数据在不可靠的 IP 网络上可靠传输。
2. 流量控制：TCP 通过滑动窗口机制调节发送方的数据发送速率，防止接收方因为处理能力有限而被数据流淹没。 
3. 拥塞控制：TCP 通过拥塞避免算法（如慢启动、拥塞避免、快速重传和快速恢复）来防止网络过载，确保网络资源的公平使用和稳定性。 
4. 连接管理：TCP 是面向连接的协议，采用三次握手（建立连接）和四次挥手（断开连接）机制来管理会话，确保通信的可靠性和状态的同步。

### 扩展知识
1. 数据包重排序与重传机制：
    - TCP 的序列号机制确保数据包按照正确的顺序组装。接收方通过序列号识别数据包的顺序，如果检测到丢失或乱序的包，会请求重传，保证数据完整性。
2. 滑动窗口与流量控制：
    - 滑动窗口用于动态调整可以发送的数据量。接收方通过发送窗口大小通告，指示发送方可以发送的最大数据量。这种机制不仅避免了接收方的溢出，还提高了数据传输效率。
3. 拥塞控制算法：  
TCP 的拥塞控制算法是核心的网络稳定性保证。经典算法包括以下几个步骤：
    - 慢启动：逐步增加发送窗口，直到检测到网络的拥塞点。 
    - 拥塞避免：当达到网络容量后，逐渐增加窗口以避免拥塞。 
    - 快速重传和快速恢复：在检测到包丢失时，立即进行重传并调整发送窗口，快速恢复正常传输状态。
4. TCP 三次握手与四次挥手：
    - 三次握手：建立连接时，双方通过三次信息交换（SYN, SYN-ACK, ACK）来确保双方都准备好进行数据传输，并协商参数（如初始序列号）。 
    - 四次挥手：断开连接时，通过四次消息交换来确保数据传输完成且资源可以安全释放，防止未传输的数据丢失。
5. TCP 的适应性与演变：
    - 随着互联网的发展，TCP 也经历了多次改进，如 TCP Reno、TCP NewReno、TCP Vegas 等，它们在拥塞控制和流量管理上有不同的策略，以适应不同的网络环境。
6. TCP 的局限性：
    - 虽然 TCP 解决了可靠传输的问题，但在高延迟、高带宽的网络（如卫星通信、现代数据中心）中可能会受到性能瓶颈，进而催生了如 QUIC 等新协议的出现。  
更多 QUIC 细节参见 HTTP 1.0 和 2.0 有什么区别？内扩展知识 HTTP 3.0 时代

### TCP 为什么可靠？
TCP 之所以被称为可靠的协议，主要是因为它提供了以下功能：

1. 数据完整性：使用校验和确保数据在传输中没有被破坏。
2. 数据顺序：保证数据按顺序到达接收方，且接收方能够重新排序乱序到达的数据。 
3. 流量控制：通过滑动窗口机制避免接收方溢出。 
4. 拥塞控制：通过动态调整发送速率避免网络拥塞。 
5. 重传机制：确保丢失的数据会被重新传输。 
6. 可靠的连接建立和关闭：通过三次握手和四次挥手确保连接的正确建立和断开。 
7. 防止数据重复：通过序列号和确认机制防止重复数据的接收。



## <font style="color:rgba(0, 0, 0, 0.88);">说说 TCP 的四次挥手？</font>


<font style="color:rgb(28, 31, 35);">TCP 的四次挥手是用于安全关闭一个已建立的连接的过程，它确保双方都能完成数据传输并安全地释放连接资源。 </font>

<font style="color:rgb(28, 31, 35);">简述步骤： </font>

<font style="color:rgb(28, 31, 35);">1) 第一次挥手（FIN → ACK）：客户端主动关闭连接，发送 FIN 包，进入 FIN_WAIT_1 状态。服务器收到 FIN 后，表示不再接收数据，但仍可能继续发送数据。 </font>

<font style="color:rgb(28, 31, 35);">2) 第二次挥手（ACK）：服务器发送 ACK 包，确认已收到 FIN。此时服务器进入 CLOSE_WAIT 状态，客户端进入 FIN_WAIT_2 状态。</font>

<font style="color:rgb(28, 31, 35);"> 3) 第三次挥手（FIN → ACK）：服务器完成所有数据传输后，发送 FIN 包，进入 LAST_ACK 状态。客户端收到 FIN 后，准备关闭连接。</font>

<font style="color:rgb(28, 31, 35);"> 4) 第四次挥手（ACK）：客户端发送最后一个 ACK 包，进入 TIME_WAIT 状态，等待可能迟到的 FIN 包。服务器收到 ACK 后，关闭连接，进入 CLOSED 状态。客户端在 TIME_WAIT 计时结束后（2MSL），正式关闭连接。 </font>

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745116186146-d84ffeff-92db-4189-ba73-138dd1c01d7e.png)



<font style="color:rgb(28, 31, 35);">为什么挥手需要四次? 主要是为了确保数据完整性。 TCP 是一个全双工协议，也就是说双方都要关闭，每一方都向对方发送 FIN 和回应 ACK。 客户端发起连接断开，代表客户端没数据要发送的，但是服务端可能还有数据没有返回给客户端。 就像我对你说我数据发完了，然后你回复好的你收到了。然后你对我说你数据发完了，然后我向你回复我收到了。这样才能保证数据不会丢失。 所以一个 FIN + ACK 代表一方结束数据的传输，因此需要两对 FIN + ACK，加起来就是四次通信。 挥手一定需要四次吗? 不一定，有时候可以变成三次挥手。 看下这张图： </font>

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745116253251-33b52220-a781-42f7-bf5e-4cea2086655b.png)

<font style="color:rgb(28, 31, 35);">正常的四次挥手流程应该很熟悉了，但是思考一下，如果 Client 发送 FIN 给 server 的时候 server 已经没数据发送给 Client 了，那么 Server 就可以将 ACK 和它的 FIN 一起发给 Client，这样一来不就变成三次挥手了吗？ </font>

## <font style="color:rgba(0, 0, 0, 0.88);">TCP 的粘包和拆包能说说吗？</font>
1. <font style="color:rgba(0, 0, 0, 0.88);">粘包与拆包（也称半包）现象：</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">粘包：指的是在 TCP 传输中，发送方的多个数据包在接收方被合并成一个包接收，导致多条消息数据粘在一起，接收方无法正确区分这些消息的边界。</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">拆包：指的是发送方的一个数据包在接收方被分成了多个包接收，导致一条完整的消息被拆成多个部分，接收方无法一次性接收到完整的数据。</font>
2. <font style="color:rgba(0, 0, 0, 0.88);">原因：</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">粘包：主要由于 TCP 是面向字节流的协议，它不关心数据边界，数据在发送方可能被一次性发送，接收方在读取时可能会将多个消息拼接在一起。</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">拆包：可能由于网络传输中的 MTU（最大传输单元）限制或发送缓冲区大小限制，一个大包被分成了多个小包传输。</font>
3. <font style="color:rgba(0, 0, 0, 0.88);">解决方法：</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">使用定长消息：每个消息都有固定的长度，接收方按照固定长度读取数据。</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">添加消息分隔符：在每个消息之间添加特定的分隔符（如换行符），接收方可以通过分隔符来区分消息。 </font>
+ <font style="color:rgba(0, 0, 0, 0.88);">使用消息头：在消息的头部添加一个长度字段，指示消息的长度，接收方根据这个长度来读取相应长度的数据。</font>

### 通俗理解粘包与拆包
这里先举个可能不太恰当，但是很容易理解的例子。

比如，平时我们要寄快递，如果东西太大的话，那么就需要拆成几个包裹来邮寄。  
收件人仅收到个别包裹的时候，东西是不完整的，对应到网络传输中，这种情况就叫半包。  
只有等接收到全部包裹时，这个东西（传输的信息）才完整，所以半包情况下无法解析出完整的数据，需要等，等接收到全部包裹。

那么问题来了，如何知晓已经收到全部包裹了呢？下文我们再作分析。

再比如，快过年了，我打算给家里的亲戚送点礼物，给每位长辈送个手表，我们都知道手表的体积不大，并且我家里人都住在一个村，所以把给各长辈的礼物打包在一个包裹里邮寄，这样能节省运费。  
这种把本应该分多个包传输的数据合成一个包发送的情况，对应到网络传输中，就叫粘包。

看完这个例子之后，应该对粘包与半包有点感觉了，接下来我们看下网络中实际的情况。

粘包与半包只有在 TCP 传输的时候才会有，像 UDP 是不会有这种情况的，原因是因为 TCP 是面向流的，数据之间没有界限的，而 UDP 是有的界限的。

如果熟悉 TCP 和 UDP 报文格式的同学肯定知道，TCP 的包没有报文长度，而 UDP 的包有报文长度，这也说明了 TCP 为什么是流式。

所以我为什么说上面的例子不太恰当，因为现实生活中快递的包裹之间其实是有界限的，TCP 则像流水，没有明确的界限。

然后 TCP 有发送缓冲区的概念，UDP 实际上是没这个概念。

假设 TCP 一次传输的数据大小超过发送缓冲区大小，那么一个完整的报文就需要被拆分成两个或更多的小报文，这可能会产生半包的情况，当接收端收到不完整的数据，是无法解析成功的。

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745117338032-6ff2957e-b541-4c93-b41d-3d5748b6c793.png)

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745117353233-a15e043d-1f81-41f5-a4ca-29373e9afb85.png)

## <font style="color:rgba(0, 0, 0, 0.88);background-color:rgb(250, 250, 250);">说说 TCP 拥塞控制的步骤？</font>


<font style="color:rgb(28, 31, 35);">主要有以下几个步骤： </font>

<font style="color:rgb(28, 31, 35);">1) 慢启动（Slow Start）： 发送方在连接建立初期，缓慢地增加数据发送速率。初始的拥塞窗口（cwnd）通常为一个 MSS（最大报文段大小），然后在每次收到 ACK 后成倍增加 cwnd，直到达到慢启动阈值（ssthresh）或检测到网络拥塞。</font>

<font style="color:rgb(28, 31, 35);"> 2) 拥塞避免（Congestion Avoidance） 当 cwnd 达到 ssthresh 后，TCP 进入拥塞避免阶段，拥塞窗口的增长速度从指数变为线性增长，即每个 RTT（往返时间）增加一个 MSS。这一阶段旨在避免激烈的拥塞反应，保持网络稳定性。</font>

<font style="color:rgb(28, 31, 35);"> 3) 快速重传（Fast Retransmit） 发送方在收到三个重复的 ACK 后，立即重传被认为丢失的报文段，而无需等待超时。这减少了重传的延迟，迅速应对数据丢失。</font>

<font style="color:rgb(28, 31, 35);"> 4) 快速恢复（Fast Recovery） 在快速重传后，TCP 不进入慢启动，而是减小 cwnd 到当前的一半，并设置 ssthresh 为当前新的 cwnd 的值，然后开始线性增加 cwnd，以快速恢复到丢包前的传输速率。</font>

<font style="color:rgb(28, 31, 35);"></font>

## <font style="color:rgba(0, 0, 0, 0.88);">TCP/IP 四层模型是什么？</font>T
TCP/IP 四层模型是一个分层网络通信模型，它将网络通信过程分为四个层次，这四层分别是：网络接口层、互联网层、传输层和应用层。

+ <font style="color:rgba(0, 0, 0, 0.88);">网络接口层负责在计算机和网络硬件之间传输数据，负责在物理网络上发送和接收数据帧，包括以太网、Wi - Fi 等协议</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">互联网层（网络层）通过 IP 协议提供数据包的路由和转发</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">传输层负责在两个主机之间提供端到端的通信服务，常见的协议有 TCP 和 UDP</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">应用层通过各种协议提供网络应用程序的功能，如 HTTP、FTP、SMTP 等协议</font>

### <font style="color:rgba(0, 0, 0, 0.88);">分层的优点</font>
+ **简化设计与实现**<font style="color:rgba(0, 0, 0, 0.88);">：通过将网络功能分解为不同的层，每一层只负责特定的任务，从而简化了设计和实现的复杂性。</font>
+ **模块化**<font style="color:rgba(0, 0, 0, 0.88);">：每一层可以独立发展和优化，不同层次之间通过标准接口进行通信，便于各层的更新和替换。 </font>
+ **互操作性**<font style="color:rgba(0, 0, 0, 0.88);">：明确定义每个层次之间的接口和协议，不同厂商或组织开发的网络设备和软件可以相互兼容，使得不同的网络设备和系统能够在不同的层次上进行无缝互操作，提升了网络的兼容性。 </font>
+ **故障隔离**<font style="color:rgba(0, 0, 0, 0.88);">：每个层次都有自己的错误检测、纠错和恢复机制，且分层结构能够帮助网络工程师定位问题所在的层次，从而更快地进行故障排除。</font>

## <font style="color:rgba(0, 0, 0, 0.88);">Cookie、Session、Token 之间有什么区别？</font>
### <font style="color:rgba(0, 0, 0, 0.88);">回答重点</font>
1. <font style="color:rgba(0, 0, 0, 0.88);">Cookie:  
</font><font style="color:rgba(0, 0, 0, 0.88);">Cookie 是存储在用户浏览器端的一个小型数据文件，用于跟踪和保存用户的状态信息。  
</font><font style="color:rgba(0, 0, 0, 0.88);">主要用于保持用户登录状态、跟踪用户行为、存储用户偏好等。  
</font><font style="color:rgba(0, 0, 0, 0.88);">存储在浏览器端。</font>
2. <font style="color:rgba(0, 0, 0, 0.88);">Session:  
</font><font style="color:rgba(0, 0, 0, 0.88);">Session 是服务器端保存用户状态的机制，每个用户会话都有一个唯一的 Session ID。  
</font><font style="color:rgba(0, 0, 0, 0.88);">主要用于跟踪用户在服务器上的状态信息，例如登录状态和购物车内容。  
</font><font style="color:rgba(0, 0, 0, 0.88);">存储在服务器端，然后对应的 Session ID 通过 Cookie 保存在客户端浏览器中。</font>
3. <font style="color:rgba(0, 0, 0, 0.88);">Token:  
</font><font style="color:rgba(0, 0, 0, 0.88);">Token 本质是一种加密的字符串，用于身份验证和授权，可以包含用户信息和权限，用于验证用户身份或授权访问资源。  
</font><font style="color:rgba(0, 0, 0, 0.88);">认证后，后端服务会返回 Token，存储在客户端（浏览器或移动应用中），后续客户端访问服务端需要带上这个 Token。</font>

<font style="color:rgba(0, 0, 0, 0.88);">它们之间使用场景区别:</font>

+ <font style="color:rgba(0, 0, 0, 0.88);">Cookie: 主要用于客户端状态的简单存储和追踪。</font>
+ <font style="color:rgba(0, 0, 0, 0.88);">Session: 用于服务器端的复杂状态管理，特别是在需要存储大量会话数据时。 </font>
+ <font style="color:rgba(0, 0, 0, 0.88);">Token: 用于无状态的认证和授权，特别是在分布式和跨域环境下。</font>

<font style="color:rgba(0, 0, 0, 0.88);">简单来说，Cookie 和 Session 更适合用于单次会话的认证和状态管理，而 Token 更适合用于跨会话的认证和状态管理。</font>

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745242373547-b4d343a0-90cf-4ff0-bd3a-94b334d78d92.png)\![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745242383448-dd275b06-da13-441a-b0e5-53f1626c0270.png)

## <font style="color:rgba(0, 0, 0, 0.88);background-color:rgb(250, 250, 250);">从网络角度来看，用户从输入网址到网页显示，期间发生了什么？</font>


<font style="color:rgb(28, 31, 35);">1. 浏览器解析 URL 浏览器会解析 URL，根据请求信息生成对应的 HTTP 请求报文。</font>

<font style="color:rgb(28, 31, 35);"> 2. DNS 解析 请求需要知晓服务器域名对应的 IP 地址才能通信，浏览器会检查本地缓存、操作系统缓存，甚至路由器缓存。如果未命中缓存，浏览器向配置的 DNS 服务器发送查询请求，DNS 服务器递归查询最终返回 IP 地址。</font>

<font style="color:rgb(28, 31, 35);"> 3. TCP 或者 UDP 接着浏览器会调用 Socket 库委托协议栈工作，根据指定的情况选择 TCP 或 UDP。 如果使用 TCP，需要通过三次握手建立连接。需要在数据发送前通过三次握手与服务端建立连接。 此时得到了封装了 HTTP 数据的 TCP 数据包。 </font>

<font style="color:rgb(28, 31, 35);">4).IP 在 TCP 数据包的基础上，再封装源地址 IP 和目标地址 IP 等信息，得到网络包。有了 IP 就能在多个网络节点中确定数据包的传输路径，最终能找到目标服务器。</font>

<font style="color:rgb(28, 31, 35);"> 5. MAC 得到网络包后，需要在 IP 头部的前面加上 MAC 头部，封装发送方 MAC 地址和接收方目标 MAC 地址。 MAC 用来确保子网内设备两点之间的通信寻址。（IP 是多个网络节点传输寻址） </font>

<font style="color:rgb(28, 31, 35);">6).网卡 这个时候，网络包还是存储在内存中的二进制数据，需要网卡把二进制数据转换为电信号，通过网线进行传输。 </font>

<font style="color:rgb(28, 31, 35);">7).交换机 通过网线会连到交换机，交换机是二层网络设备。工作在 MAC 层，它会根据数据包中的 MAC 头找到另一个设备连接在交换机的哪个端口，然后传输。 如果找不到对应的端口，则会向交换机上的所有端口(除了源端口)广播。 </font>

<font style="color:rgb(28, 31, 35);">8. 路由器 路由器也是进行转发，但它是三层网络设备，包含 IP 层。利用路由器，数据在不同网络节点之间转发，最后到达服务器。 </font>

<font style="color:rgb(28, 31, 35);">9).层层验证 服务器确认 MAC 地址匹配、IP 地址匹配，如果是 TCP 协议则看看序列号是否匹配，若匹配根据端口找到对应的监听进程，此时服务器上对应的应用就接收到数据了。 </font>

<font style="color:rgb(28, 31, 35);">10. 服务器处理 服务器接收到请求后，处理相应的业务逻辑，生成 HTTP 响应。这其间可能涉及到读取数据库、访问文件系统等。最终会生成响应给客户端（又是一层一层的封装 TCP、IP、MAC 等头部数据，得到最终传输的数据包），从网卡到交换机到路由器…… </font>

<font style="color:rgb(28, 31, 35);">11. 浏览器接收响应并渲染页面 经过多个路由器转发后，浏览器最终会接收到服务器返回的响应，进行页面渲染展示。 </font>

<font style="color:rgb(28, 31, 35);"> </font>![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745242971971-bd28db1c-4550-4837-a41b-c7abe1c17cba.png)

## <font style="color:rgba(0, 0, 0, 0.88);">I/O模型有哪些？</font>
常见的I/O模型有以下几种：

+ 阻塞I/O（Blocking I/O）：调用I/O操作时，进程会被阻塞，直到数据准备好或操作完成后才继续执行。
+ 非阻塞I/O（Non - blocking I/O）：I/O操作不会阻塞进程，如果数据没有准备好，立即返回错误或状态，进程可以继续执行其他操作。 
+ I/O多路复用（I/O Multiplexing）：使用select、poll、epoll等系统调用，允许程序同时等待多个I/O操作，当其中任意一个就绪时进行处理。 
+ 信号驱动I/O（Signal - driven I/O）：在数据准备好时，内核通过信号通知进程进行I/O操作，进程在接收到信号后再进行数据读取或写入。 
+ 异步I/O（Asynchronous I/O）：发起I/O请求后立即返回，内核在后台完成I/O操作，并在操作完成时通知进程。进程不需要等待I/O完成即可继续执行其他任务。

阻塞的执行单元解释：如果是单线程的程序用进程来描述合适一些，即称之为进程会被阻塞。如果多线程的程序用线程合适一些，即称之为线程会被阻塞

### **同步阻塞I/O**
![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745417856470-4d85cc57-7ccd-4790-b2fe-d4547bf7e51c.png)

<font style="color:rgb(28, 31, 35);">当用户程序的线程调用read获取网络数据的时候，首先这个数据得有，也就是网卡得先收到客户端的数据，然后这个数据有了之后需要拷贝到内核中，然后再被拷贝到用户空间内，这整一个过程用户线程都是被阻塞的。 假设没有客户端发数据过来，那么这个用户线程就会一直阻塞等着，直到有数据。即使有数据，那么两次拷贝的过程也得阻塞等着。 所以这称为同步阻塞I/O模型。 它的优点很明显，简单。调用read之后就不管了，直到数据来了且准备好了进行处理即可。 缺点也很明显，一个线程对应一个连接，一直被霸占着，即使网卡没有数据到来，也同步阻塞等着。 我们都知道线程是属于比较重资源，这就有点浪费了。 所以我们不想让它这样傻等着。 于是就有了同步非阻塞I/O。 </font>

### <font style="color:rgb(28, 31, 35);">同步阻塞I/O</font>
![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745417962671-0fe823d6-9aca-4afc-8742-98d118c0cc2c.png)

<font style="color:rgb(28, 31, 35);"></font>

<font style="color:rgb(28, 31, 35);">从图中我们可以很清晰的看到，同步非阻塞I/O 基于同步阻塞I/O 进行了优化： 在没数据的时候可以不再傻傻地阻塞等着，而是直接返回错误，告知暂无准备就绪的数据！ 这里要注意，从内核拷贝到用户空间这一步，用户线程还是会被阻塞的。 这个模型相比于同步阻塞I/O 而言比较灵活，比如调用read如果暂无数据，则线程可以先去干干别的事情，然后再来继续调用read看看有没有数据。 但是如果你的线程就是取数据然后处理数据，不干别的逻辑，那这个模型又有点问题了。 等于你不断地进行系统调用，如果你的服务器需要处理海量的连接，那么就需要有海量的线程不断调用，上下文切换频繁，CPU 也会忙死，做无用功而忙死。 那怎么办？ 于是就有了I/O 多路复用 </font>

### <font style="color:rgb(28, 31, 35);">I/O 多路复用 </font>
![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745418011737-5f21639f-6a3b-465c-b38e-4596cda29c7f.png)

<font style="color:rgb(28, 31, 35);">从图上来看，好像和上面的同步非阻塞I/O差不多啊，其实不太一样，线程模型不一样。 既同步非阻塞I/O在太多的连接下频繁调用太浪费了，那就招个专员吧。 这个专员工作就是管理多个连接，帮忙查看连接上是否有数据已准备就绪。 也就是说，可以只用一个线程查看多个连接是否有数据已准备就绪。 具体到代码上，这个专员就是select，我们可以往select注册需要被监听的连接，由select来监控它所管理的连接是否有数据已就绪，如果有则可以通知别的线程来read读取数据，这个read和之前的一样，还是会阻塞用户线程。 这样一来就可以用少量的线程去监控多条连接，减少了线程的数量，降低了内存的消耗且减少了上下文切换的次数，很舒服。 想必到此你已经理解了什么叫I/O多路复用。 所谓的多路指的是多条连接，复用指的是用一个线程就可以监控这么多条连接。 看到这，你再想想，还有什么地方可以优化的？ </font>

### <font style="color:rgb(28, 31, 35);">信号驱动I/O</font>
![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745418065994-ee0d3e5d-9f0c-4332-b43a-8545f31133bd.png)

<font style="color:rgb(28, 31, 35);">上面的select虽然不阻塞了，但是他得时刻去查询看看是否有数据已经准备就绪，那是不是可以让内核告诉我们数据到了而不是我们去轮询呢？ 信号驱动I/O就能实现这个功能，由内核告知数据已准备就绪，然后用户线程再去read（还是会阻塞）。 听起来是不是比I/O多路复用好呀？那为什么好像很少听到信号驱动I/O？ 为什么市面上用的都是I/O多路复用而不是信号驱动？ 因为我们的应用通常用的都是TCP协议，而TCP协议的socket可以产生信号事件有七种。 也就是说不仅仅只有数据准备就绪才会发信号，其他事件也会发信号，而这个信号又是同一个信号，所以我们的应用程序无从区分到底是什么事件产生的这个信号。 那就麻了呀！ 所以我们的应用基本上用不了信号驱动I/O，但如果你的应用程序用的是UDP协议，那是可以的，因为UDP没这么多事件。 因此，这么一看对我们而言信号驱动I/O也不太行。 </font>

### <font style="color:rgb(28, 31, 35);">异步I/O</font>
<font style="color:rgb(28, 31, 35);">信号驱动I/O虽然对TCP不太友好，但是这个思路对的：往异步发展，但是它并没有完全异步，因为其后面那段read还是会阻塞用户线程，所以它算是半异步。</font>

<font style="color:rgb(28, 31, 35);">因此，我们得想下如何弄成全异步的，也就是把read那步阻塞也省了。</font>

<font style="color:rgb(28, 31, 35);">其实思路很清晰：让内核直接把数据拷贝到用户空间之后再告知用户线程，来实现真正的非阻塞I/O！</font>

![](https://cdn.nlark.com/yuque/0/2025/png/32795398/1745418213476-c59ffa47-152d-460a-ae84-7195f344432f.png)

<font style="color:rgb(28, 31, 35);">所以异步I/O其实就是用户线程调用aio_read，然后包括将数据从内核拷贝到用户空间那步，所有操作都由内核完成，当内核操作完毕之后，再调用之前设置的回调，此时用户线程就拿着已经拷贝到用户控件的数据可以继续执行后续操作。 在整个过程中，用户线程没有任何阻塞点，这才是真正的非阻塞I/O。 </font>

## <font style="color:rgba(0, 0, 0, 0.88);">Select、Poll、Epoll 之间有什么区别？</font>
它们都是操作系统中用于多路复用I/O的机制：

### select：
+ 早期的I/O多路复用机制，使用固定长度的数组表示文件描述符集。每次调用select时都需要重新构建和检查文件描述符集。
+ 支持的文件描述符数量有限（通常为1024），在大规模连接的场景下效率较低。

### poll：
+ poll与select类似，但使用动态数组来存储文件描述符，因此没有select的最大连接数限制。 
+ 每次调用时仍需遍历全部描述符，在处理大量连接时效率不高。

### epoll：
+ epoll是Linux系统对select和poll的优化，提供了边缘触发（ET）和水平触发（LT）模式。 
+ 不会遍历所有文件描述符，而是通过事件通知的方式，只处理实际发生变化的描述符，适合高并发服务器。 
+ epoll在注册文件描述符后，只需调用一次添加操作，后续的事件管理更高效。

### 扩展知识
#### select
select函数使用一个固定大小的位图来表示文件描述符集，通过将文件描述符的状态（如可读、可写）存储在一个数组中，调用select时检查这些描述符的状态。  
每次调用select时，程序需要重新构建位图，并将所有文件描述符集传递给内核检查状态，判断是否有I/O操作就绪。  
**局限**：

+ 文件描述符限制：通常为1024（可以通过修改系统参数调整），限制了并发处理的数量。
+ 性能低：在高并发场景中，每次都需要遍历整个文件描述符集进行检查，性能开销大。
+ 不适合高并发场景：随着连接数的增加，select的效率会急剧下降，因为每次调用都需要线性扫描整个文件描述符集。

#### poll
poll使用一个动态数组来管理文件描述符，能够支持更多的连接数。每个文件描述符有一个对应的结构体（pollfd），包含文件描述符和事件类型。  
调用poll时，程序传入的描述符数组会被内核修改，以反映当前文件描述符的状态。  
**改进**：

+ 打破文件描述符数量限制：poll不再依赖于固定大小的位图，可以支持任意数量的文件描述符。
+ 接口更灵活：比select更灵活，适合大部分网络应用场景。  
**不足**：
+ 每次调用时仍需遍历所有描述符：即使只有少数描述符发生变化，也需要检查整个数组。
+ 性能开销较大：在大规模并发场景下，性能问题依然存在。

#### epoll
epoll使用一个内核空间的事件列表，应用程序可以通过epoll_ctl向epoll实例注册、修改或删除感兴趣的文件描述符及其事件。  
调用epoll_wait时，只会返回发生事件的文件描述符，而不是检查所有描述符。

### 优势：
1. **事件驱动模型**：epoll基于事件驱动，不再像select和poll那样需要线性扫描所有描述符。只有当注册的事件发生时，epoll才会通知应用程序。
2. **边缘触发与水平触发**：
    - **水平触发（LT, Level Triggered）**：是默认模式，类似于select / poll的工作方式，只要文件描述符上有未处理的数据，每次调用epoll_wait都会返回该文件描述符。
    - **边缘触发（ET, Edge Triggered）**：仅在状态发生变化时通知一次，需要用户在事件发生时读取所有数据，否则可能会错过后续事件。减少了重复事件通知的次数，但增加了编程的复杂度，通常需要结合非阻塞I/O使用。
3. **内存映射**：epoll通过内存映射（mmap）减少了在内核和用户空间之间的数据复制，进一步提高了性能。

### select底层原理分析
select的核心数据结构：文件描述符集合（fd_set），用来管理需要监视的文件描述符。  
fd_set本质上是一个位图，位图中的每一位对应一个文件描述符的状态。大小为1024位（与FD_SETSIZE定义相关），每一位表示一个文件描述符。位图中的每一位的值为1表示该文件描述符需要监视，为0表示不需要监视。  
再了解下三种监视类型，分别存储在不同的fd_set中：

+ **可读事件（readfds）**：监视文件描述符是否有数据可读。
+ **可写事件（writefds）**：监视文件描述符是否可写（即是否可以发送数据）。 
+ **异常事件（exceptfds）**：监视文件描述符上是否有异常情况（如带外数据）。

select的操作流程如下

1. **构建fd_set并调用select**：  
在调用select之前，程序需要根据需要监视的文件描述符和事件类型，将文件描述符添加到readfds、writefds或exceptfds中。



```markdown
int poll(struct pollfd *fds, nfds_t nfds, int timeout);

```

+ **fds**：指向pollfd结构体数组的指针。
+ **nfds**：表示数组中元素的数量（即需要监视的文件描述符的数量）。
+ **timeout**：指定poll等待的超时时间，以毫秒为单位。
2. **进入内核态进行检查**：  
调用poll后，程序会从用户态切换到内核态。内核会遍历fds数组中的所有文件描述符，检查它们的状态是否与events字段中的感兴趣事件匹配。  
内核会逐一检查每个文件描述符，判断其当前状态是否有数据可读、可写，或是否发生了错误等。
3. **阻塞等待或超时**：  
如果在遍历过程中，没有找到任何就绪的文件描述符，则poll会根据timeout参数进行阻塞等待。
+ **阻塞等待**：如果timeout为 -1，poll会无限期地等待，直到有文件描述符的状态发生变化。
+ **非阻塞调用**：如果timeout为0，poll会立即返回，即使没有文件描述符发生状态变化。
4. **更新revents字段并返回**：  
当文件描述符的状态与指定的events匹配时，poll会将实际发生的事件写入revents字段。  
poll返回时，会返回就绪文件描述符的数量，程序可以遍历fds数组，检查revents字段以确定哪些文件描述符发生了事件。

## <font style="color:rgba(0, 0, 0, 0.88);">为什么网络 I/O 会被阻塞？</font>
网络I/O会被阻塞是因为在进行网络数据传输时，操作系统在等待数据的发送或接收完成之前，会将进程挂起，直到数据传输完成后才恢复进程执行。

阻塞的主要原因是：

+ **等待数据到达或发送完成**：当进程尝试从网络套接字中读取数据时，如果数据尚未到达，操作系统会使进程进入阻塞状态，直到数据到达为止。同样，当数据未能立即发送出去时，发送操作也可能被阻塞，等待缓冲区有空闲空间。
+ **系统资源有限**：当系统资源（如网络缓冲区、连接数等）被占满时，进一步的I/O请求可能会被阻塞，等待资源释放后才能继续。 
+ **默认的阻塞行为**：大多数网络API（如recv、send、accept等）在默认情况下都是阻塞的，即调用这些API时，如果条件不满足，会使调用者等待，直到I/O操作完成。



